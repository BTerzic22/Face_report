{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from matplotlib import patches\n",
    "from PIL import Image\n",
    "from skimage import color, measure, data, feature\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.feature import Cascade\n",
    "from skimage.transform import resize, rescale\n",
    "import glob, sys\n",
    "import io\n",
    "from pdf2image import convert_from_path\n",
    "from pdf2image.exceptions import (\n",
    "    PDFInfoNotInstalledError,\n",
    "    PDFPageCountError,\n",
    "    PDFSyntaxError \n",
    ")\n",
    "from PyPDF2 import PdfReader\n",
    "import cv2\n",
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multipass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_collector():\n",
    "    os.getcwd()\n",
    "    file = glob.glob(\"*.pdf\")\n",
    "    file.sort(key=os.path.getmtime)\n",
    "    pdf_files = list(file)\n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pdf to png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_png(pdf_path):\n",
    "  #poppler_path = \"/home/bmt22/poppler-0.68.0/bin\"\n",
    "  images = convert_from_path(pdf_path=pdf_path)\n",
    "  for count, img in enumerate(images):\n",
    "    img_name = f\"page_{count}.png\"  \n",
    "    img.save(img_name, \"PNG\")\n",
    "  return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_face_detector():\n",
    "    # Load the trained file from the module root.\n",
    "    trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "    # Initialize the detector cascade.\n",
    "    detector = Cascade(trained_file)\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(images, detector):\n",
    "    for i in range(len(images)):\n",
    "        #image = Image.open(i)\n",
    "        npim = np.array(images[i], dtype='uint8' )\n",
    "        detected = detector.detect_multi_scale(img=npim, scale_factor=1.2, step_ratio=1, min_size=(1000, 800), max_size=(2000, 1500))\n",
    "        if len(detected) != 0:\n",
    "            break\n",
    "    return npim, images[i] #, images[i+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.imshow(npim)\n",
    "img_desc = plt.gca()\n",
    "plt.set_cmap('gray')\n",
    "\n",
    "for patch in detected:\n",
    "\n",
    "    img_desc.add_patch(\n",
    "        patches.Rectangle(\n",
    "            (patch['c'], patch['r']),\n",
    "            patch['width'],\n",
    "            patch['height'],\n",
    "            fill=False,\n",
    "            color='r',\n",
    "            linewidth=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bordure detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bordure_detection(face):\n",
    "  # Read image\n",
    "  #face = cv2.imread(path)\n",
    "  \n",
    "  # Convert image to grayscale\n",
    "  gray = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "  # Use canny edge detection\n",
    "  edges = cv2.Canny(gray,50,150,apertureSize=3)\n",
    "  \n",
    "  # Apply HoughLinesP method to\n",
    "  # to directly obtain line end points\n",
    "  #lines_list = list()\n",
    "  lines = cv2.HoughLinesP(\n",
    "              edges, # Input edge image\n",
    "              1, # Distance resolution in pixels\n",
    "              np.pi/180, # Angle resolution in radians\n",
    "              threshold=100, # Min number of votes for valid line\n",
    "              minLineLength=130, # Min allowed length of line\n",
    "              maxLineGap=10 # Max allowed gap between line for joining them\n",
    "              )\n",
    "  X, Y = list(), list()\n",
    "  # Iterate over points\n",
    "  for points in lines:\n",
    "      # Extracted points nested in the list\n",
    "      x1,y1,x2,y2=points[0]\n",
    "      # Draw the lines joing the points\n",
    "      # On the original image\n",
    "      if x1 == x2 :\n",
    "        # Maintain a simples lookup list for points\n",
    "        cv2.line(face,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "        X.append(x1); X.append(x2)\n",
    "        Y.append(y1); Y.append(y2)\n",
    "  # Save the result image\n",
    "  #cv2.imwrite('detectedLines.png',face)\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_croping(X, Y, img):\n",
    "    left = np.min(X)\n",
    "    top = np.min(Y)\n",
    "    right = np.max(X)\n",
    "    bottom = np.max(Y)\n",
    "    #height = np.shape(etalon)[0]\n",
    "    #width = np.shape(etalon)[1]\n",
    "    delta = 30\n",
    "\n",
    "    img_res = img.crop((left - delta, top - delta, right + delta, bottom + delta)) \n",
    "    #final_res = np.array(img_res, dtype='uint8' )\n",
    "    #final_res = resize(final_res, (height, width), anti_aliasing=True)\n",
    "    return img_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation detection and storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(im_with_face):\n",
    "    # Convert from RGB-VGA to RGB format\n",
    "    im_test_rgb = im_with_face.convert('RGB')\n",
    "\n",
    "    # Convert into grayscale image\n",
    "    im_test_gray = color.rgb2gray(im_test_rgb)\n",
    "\n",
    "    # Use threshold otsu to be able to find contours\n",
    "    thresh = threshold_otsu(im_test_gray)\n",
    "    im_thresh = im_test_gray > thresh\n",
    "    contours = measure.find_contours(im_thresh, 0.8)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(im_thresh, cmap=plt.cm.gray)\n",
    "    for contour in contours:\n",
    "        #if contour.shape < (130, 2) and contour.shape > (15, 2):\n",
    "        plt.plot(contour[:,1], contour[:,0], linewidth=1)\n",
    "    ax.axis('image')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.show()\n",
    "    return contours, im_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration():\n",
    "    path = '/home/bmt22/Face report/Reference/Reference.PNG' \n",
    "    sample = Image.open(path)\n",
    "    np_sample = np.array(sample)\n",
    "    X_cal, Y_cal = bordure_detection(np_sample)\n",
    "    img_res = im_croping(X_cal, Y_cal, sample)\n",
    "    contours_cal, im_thresh = find_contours(img_res)\n",
    "    return contours_cal, im_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(im_thresh, cmap=plt.cm.gray)\n",
    "plt.scatter(im_thresh.shape[1]*2/5, im_thresh.shape[0]*2/5, marker='*')\n",
    "\n",
    "ax.axis('image')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_contours(contours_storage):\n",
    "    for contour in contours:\n",
    "        if contour.shape < (130, 2):\n",
    "            col_center = np.mean(contour[:, 1])\n",
    "            row_center = np.mean(contour[:, 0])\n",
    "            if row_center > im_thresh.shape[1] * 2/5:\n",
    "                contours_storage.append(contour)\n",
    "            elif col_center < im_thresh.shape[0] * 3/5 and col_center > im_thresh.shape[0] * 2/5:\n",
    "                contours_storage.append(contour)\n",
    "    return contours_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdf_to_png' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/bmt22/Face_report/src/Face_reco_lab.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bmt22/Face_report/src/Face_reco_lab.ipynb#ch0000019?line=1'>2</a>\u001b[0m contours_storage, contours \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(), \u001b[39mlist\u001b[39m()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bmt22/Face_report/src/Face_reco_lab.ipynb#ch0000019?line=2'>3</a>\u001b[0m pdf_files \u001b[39m=\u001b[39m pdf_collector()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bmt22/Face_report/src/Face_reco_lab.ipynb#ch0000019?line=3'>4</a>\u001b[0m images \u001b[39m=\u001b[39m pdf_to_png(pdf_files[\u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bmt22/Face_report/src/Face_reco_lab.ipynb#ch0000019?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m init \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bmt22/Face_report/src/Face_reco_lab.ipynb#ch0000019?line=5'>6</a>\u001b[0m     detector \u001b[39m=\u001b[39m init_face_detector()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pdf_to_png' is not defined"
     ]
    }
   ],
   "source": [
    "init=0\n",
    "contours_storage, contours = list(), list()\n",
    "pdf_files = pdf_collector()\n",
    "images = pdf_to_png(pdf_files[1])\n",
    "if init == 0:\n",
    "    detector = init_face_detector()\n",
    "    init += 1\n",
    "np_im_with_face, im_with_face = face_detector(images, detector)\n",
    "X, Y = bordure_detection(np_im_with_face)\n",
    "img_res = im_croping(X, Y, im_with_face)\n",
    "contours_cal, im_thresh = calibration()\n",
    "contours = find_contours(img_res)\n",
    "contours_storage = store_contours(contours_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for contour in contours:\n",
    "#    print(contour.shape)\n",
    "len(contours[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do\n",
    "-   Organiser le répertoire\n",
    "-   Build project\n",
    "-   Mettre images dans un tmp\n",
    "-   Supprimer images après usage\n",
    "-   Pourquoi contours est devenu une liste de contours ??\n",
    "-   Voir si utiliser var ou std pour identifier croix / rond\n",
    "-   Flask pour serveur: associe un url à une fonction pour partage pdf de portrait"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e753736276f1fa3123c6ce6c08b881f900c1a1a70bd6567e9aad90eb06f43058"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
